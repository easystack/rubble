apiVersion: v1
kind: ServiceAccount
metadata:
  name: rubble
  namespace: kube-system

---

kind: ClusterRole
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: rubble-pod-reader
  namespace: kube-system
rules:
  - apiGroups: [ "" ]
    resources: [ "pods", "nodes", "namespaces", "configmaps", "serviceaccounts" ]
    verbs: [ "get", "watch", "list", "update" ]
  - apiGroups: [ "" ]
    resources:
      - events
    verbs:
      - create
  - apiGroups: [ "networking.k8s.io" ]
    resources:
      - networkpolicies
    verbs:
      - get
      - list
      - watch
  - apiGroups: [ "coordination.k8s.io" ]
    resources: [ "leases" ]
    verbs: [ "get", "watch", "update", "create" ]
  - apiGroups: [ "extensions" ]
    resources:
      - networkpolicies
    verbs:
      - get
      - list
      - watch
  - apiGroups: [ "" ]
    resources:
      - pods/status
    verbs:
      - update
  - apiGroups: [ "crd.projectcalico.org" ]
    resources: [ "*" ]
    verbs: [ "*" ]
  - apiGroups: [ "discovery.k8s.io" ]
    resources:
      - endpointslices
    verbs:
      - get
      - list
      - watch
  - apiGroups: [ "" ]
    resources:
      - endpoints
      - services
    verbs:
      - get
      - list
      - watch
  - apiGroups: [ "" ]
    resources:
      - nodes
      - nodes/status
    verbs:
      - patch
  - apiGroups:
      - apiextensions.k8s.io
    resources:
      - customresourcedefinitions
    verbs:
      - create
      - get
      - list
      - watch
      - update
  - apiGroups:
      - cilium.io
    resources:
      - '*'
    verbs:
      - '*'
---

apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: rubble-binding
  namespace: kube-system
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: rubble-pod-reader
subjects:
  - kind: ServiceAccount
    name: rubble
    namespace: kube-system

---

kind: ConfigMap
apiVersion: v1
metadata:
  name: kube-rubble-config
  namespace: kube-system
data:
  init.sh: |
    #!/bin/bash
    set -x
    init_node_bpf() {
      nsenter -t 1 -m -- bash -c '
      mount | grep "/sys/fs/bpf type bpf" || {
      # Mount the filesystem until next reboot
      echo "Mounting BPF filesystem..."
      mount bpffs /sys/fs/bpf -t bpf
    
      echo "Link information:"
      ip link
    
      echo "Routing table:"
      ip route
    
      echo "Addressing:"
      ip -4 a
      ip -6 a
    #  date > /tmp/cilium-bootstrap-time
      echo "Node initialization complete"
    }'
    }
    
    set -o errexit
    set -o nounset
    
    # install CNIs
    cp -f /usr/bin/rubble /opt/cni/bin/
    chmod +x /opt/cni/bin/rubble
    cp -f /usr/bin/cilium-cni /opt/cni/bin/
    chmod +x /opt/cni/bin/cilium-cni
    #chmod +x /bin/policyinit.sh
    
    #ENIIP_VIRTUAL_TYPE=$(jq .eniip_virtual_type? -r < /etc/eni/10-terway.conf | tr '[:upper:]' '[:lower:]')
    ENIIP_VIRTUAL_TYPE="ipvlan"
    
    if [ "$ENIIP_VIRTUAL_TYPE" = "ipvlan" ]; then
      # check kernel version & enable cilium
      KERNEL_MAJOR_VERSION=$(uname -r | awk -F . '{print $1}')
      KERNEL_MINOR_VERSION=$(uname -r | awk -F . '{print $2}')
      # kernel version equal and above 4.19
      if { [ "$KERNEL_MAJOR_VERSION" -eq 4 ] && [ "$KERNEL_MINOR_VERSION" -ge 19 ]; } ||
         [ "$KERNEL_MAJOR_VERSION" -gt 4 ]; then
    
        echo "Init node BPF"
        init_node_bpf
    #    echo "Creating 10-terway.conflist"
    #
    #    BANDWIDTH_MODE=tc
    #    if bpftool -j feature probe | grep bpf_skb_ecn_set_ce ; then
    #      BANDWIDTH_MODE=edt
    #    fi
    	
    #
    #    jq --arg bandwidth_mode "$BANDWIDTH_MODE" '. |= . + {
    #      "bandwidth_mode": $bandwidth_mode
    #    }' < /etc/eni/10-terway.conf | jq '
    #    {
    #      "cniVersion": "0.3.1",
    #      "name": "terway-chainer",
    #      "plugins": [
    #          del(.name,.cniVersion),
    #          {
    #             "type": "cilium-cni"
    #          }
    #       ]
    #    }' > /etc/cni/net.d/10-terway.conflist
    #
    #  rm -f /etc/cni/net.d/10-terway.conf || true
    #  
        #cp /etc/kube-rubble/10-rubble.conf /etc/cni/net.d/10-rubble.conf
      else
        echo "Linux kernel version <= 4.19, skipping cilium config"
    #    cp /etc/eni/10-terway.conf /etc/cni/net.d/
      fi
    #else
    #  rm -f /etc/cni/net.d/10-terway.conflist || true
    #  cp /etc/eni/10-terway.conf /etc/cni/net.d/
    fi
    
    # sysctl -w net.ipv4.conf.eth0.rp_filter=0 # sysctl: cannot stat /proc/sys/net/ipv4/conf/eth0/rp_filter: No such file or directory
    modprobe sch_htb || true
    chroot /host sh -c "ls -l /etc/udev/rules.d/; ls -l /lib/udev/rules.d/; ls -l /lib/udev/; rm -f /etc/udev/rules.d/75-persistent-net-generator.rules /lib/udev/rules.d/60-net.rules /lib/udev/rules.d/61-eni.rules /lib/udev/write_net_rules && udevadm control --reload-rules && udevadm trigger" 
  policyinit.sh: |
    #!/usr/bin/bash

    set -x
    if [ -z "$DISABLE_POLICY" ] || [ "$DISABLE_POLICY" = "false" ] || [ "$DISABLE_POLICY" = "0" ]; then
      ENABLE_POLICY="default"
    else
      ENABLE_POLICY="never"
    fi

    extra_args=""

    if bpftool -j feature probe | grep bpf_skb_ecn_set_ce ; then
        extra_args="${extra_args} --enable-bandwidth-manager=true "
    fi
      cilium preflight register-crd --k8s-kubeconfig-path /root/.kube/config
      echo "using cilium as network routing & policy"
      # shellcheck disable=SC2086
      exec cilium-agent --tunnel=disabled --enable-ipv4-masquerade=false --enable-ipv6-masquerade=false \
            --enable-policy=$ENABLE_POLICY \
            --agent-health-port=9099 --disable-envoy-version-check=true \
            --enable-local-node-route=false --ipv4-range=auto --enable-endpoint-health-checking=false \
            --enable-health-checking=false --enable-service-topology=true --disable-cnp-status-updates=true --k8s-heartbeat-timeout=0 --enable-session-affinity=true \
            --install-iptables-rules=false --enable-l7-proxy=false --enable-identity-mark=true --k8s-kubeconfig-path=/root/.kube/config \
            --kube-proxy-replacement=partial \
            --ipam=cluster-pool ${extra_args}
    # exec failed in init.sh, exec here
    sysctl -w net.ipv4.conf.eth0.rp_filter=0
  rubble.json: |
    {
      "service_cidr": "10.222.0.0/16",
      "net_id": "share_net",
      "subnet_id": "share_net__subnet",
      "max_pool_size": 30,
      "min_pool_size": 0,
      "max_idle_size": 10,
      "min_idle_size": 5,
      "node_name": "node-2",
      "period": 30
    }
  10-rubble.conflist: |
    {
        "cniVersion": "0.3.1",
        "name": "rubble-chainer",
        "plugins": [
          {
            "type": "rubble",
            "ipMasq": true,
            "master": "ens3"
          },
          {
            "type": "cilium-cni"
          }
        ]

    }
  disable_network_policy: "false"
  os_auth_url: "http://keystone.openstack.svc.cluster.local/v2.0"
  os_domain_name: "Default"
  os_project_name: "service"
  os_user_domain_name: "Default"
  os_username: "drone"
  os_password: "fHknJldf"

---

apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: rubble
  namespace: kube-system
spec:
  selector:
    matchLabels:
      app: rubble
  template:
    metadata:
      labels:
        app: rubble
      annotations:
        priorityClassName: ''
    spec:
      hostPID: true
      nodeSelector:
        kubernetes.io/arch: amd64
      tolerations:
        - operator: "Exists"
      terminationGracePeriodSeconds: 0
      serviceAccountName: rubble
      hostNetwork: true
      initContainers:
        - name: rubble-init
          image: hub.easystack.cn/cni-devops/rubble:latest
          imagePullPolicy: IfNotPresent
          securityContext:
            privileged: true
          command:
            - '/bin/init.sh'
          volumeMounts:
            - name: rubble-config
              mountPath: /etc/kube-rubble/
            - name: cni-bin
              mountPath: /opt/cni/bin/
            - name: cni
              mountPath: /etc/cni/net.d/
            - mountPath: /lib/modules
              name: lib-modules
            - mountPath: /host
              name: host-root
            - name: rubble-init
              mountPath: '/bin/init.sh'
              subPath: init.sh
      containers:
        - name: rubble-daemon
          image: hub.easystack.cn/cni-devops/rubble:latest
          imagePullPolicy: IfNotPresent
          command: [ '/usr/bin/rubble-daemon', '--kube-config=/root/.kube/config' ]
          securityContext:
            privileged: true
          env:
            - name: NODE_NAME
              valueFrom:
                fieldRef:
                  fieldPath: spec.nodeName
            - name: POD_NAMESPACE
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
            - name: OS_AUTH_URL
              valueFrom:
                configMapKeyRef:
                  name: kube-rubble-config
                  key: os_auth_url
            - name: OS_DOMAIN_NAME
              valueFrom:
                configMapKeyRef:
                  name: kube-rubble-config
                  key: os_domain_name
            - name: OS_PROJECT_NAME
              valueFrom:
                configMapKeyRef:
                  name: kube-rubble-config
                  key: os_project_name
            - name: OS_USER_DOMAIN_NAME
              valueFrom:
                configMapKeyRef:
                  name: kube-rubble-config
                  key: os_user_domain_name
            - name: OS_USERNAME
              valueFrom:
                configMapKeyRef:
                  name: kube-rubble-config
                  key: os_username
            - name: OS_PASSWORD
              valueFrom:
                configMapKeyRef:
                  name: kube-rubble-config
                  key: os_password                  
          volumeMounts:
            - name: daemonconfig
              mountPath: /etc/cni/rubble/
            - name: rubble-config
              mountPath: /etc/kube-rubble/
            - mountPath: /var/run/
              name: rubble-run
            - mountPath: /lib/modules
              name: lib-modules
            - mountPath: /var/lib/cni/networks
              name: cni-networks
            - mountPath: /var/lib/cni/rubble
              name: cni-rubble
            - mountPath: /var/lib/kubelet/device-plugins
              name: device-plugin-path
            - mountPath: /root/.kube/config
              name: kubeconfig
        - name: policy
          image: hub.easystack.cn/cni-devops/rubble:latest
          imagePullPolicy: IfNotPresent
          command: [ "/bin/policyinit.sh" ]
          env:
            - name: NODENAME
              valueFrom:
                fieldRef:
                  fieldPath: spec.nodeName
            - name: DISABLE_POLICY
              valueFrom:
                configMapKeyRef:
                  name: kube-rubble-config
                  key: disable_network_policy
                  optional: true
            - name: K8S_NODE_NAME
              valueFrom:
                fieldRef:
                  apiVersion: v1
                  fieldPath: spec.nodeName
            - name: CILIUM_K8S_NAMESPACE
              valueFrom:
                fieldRef:
                  apiVersion: v1
                  fieldPath: metadata.namespace
            - name: CILIUM_CNI_CHAINING_MODE
              value: rubble-chainer
            - name: KUBECONFIG_PATH_FILE
              value: "/root/.kube/config"
          securityContext:
            privileged: true
          resources:
            requests:
              cpu: 250m
          livenessProbe:
            tcpSocket:
              port: 9099
              host: localhost
            periodSeconds: 10
            initialDelaySeconds: 10
            failureThreshold: 6
          readinessProbe:
            tcpSocket:
              port: 9099
              host: localhost
            periodSeconds: 10
          volumeMounts:
            - mountPath: /lib/modules
              name: lib-modules
            - mountPath: /etc/cni/net.d
              name: cni
            - name: rubble-config
              mountPath: /etc/kube-rubble/              
            # volumes use by cilium
            - mountPath: /sys/fs/bpf
              name: bpf-maps
            - mountPath: /var/run/cilium
              name: cilium-run
              # Needed to be able to load kernel modules
            - mountPath: /run/xtables.lock
              name: xtables-lock
            - mountPath: /root/.kube/config
              name: kubeconfig
            - mountPath: "/bin/policyinit.sh"
              name: policyinit-script
              subPath: policyinit.sh
      volumes:
        - name: daemonconfig
          configMap:
            name: kube-rubble-config
            items:
              - key: rubble.json
                path: rubble.json
        - name: rubble-config
          configMap:
            name: kube-rubble-config
            items:
              - key: 10-rubble.conflist
                path: 10-rubble.conflist
        - name: policyinit-script
          configMap:
            defaultMode: 0755
            name: kube-rubble-config
            items:
              - key: policyinit.sh
                path: policyinit.sh
        - name: rubble-init
          configMap:
            defaultMode: 0755
            name: kube-rubble-config
            items:
              - key: init.sh
                path: init.sh
        - name: cni-bin
          hostPath:
            path: /opt/cni/bin
            type: "Directory"
        - name: cni
          hostPath:
            path: /etc/cni/net.d
            type: "Directory"
        - name: rubble-run
          hostPath:
            path: /var/run/
            type: "Directory"
        - name: lib-modules
          hostPath:
            path: /lib/modules
            type: "Directory"
        - name: cni-networks
          hostPath:
            path: /var/lib/cni/networks
        - name: cni-rubble
          hostPath:
            path: /var/lib/cni/rubble
        - name: device-plugin-path
          hostPath:
            path: /var/lib/kubelet/device-plugins
            type: "Directory"
        - name: host-root
          hostPath:
            path: /
            type: "Directory"
        # used by cilium
        # To keep state between restarts / upgrades
        - hostPath:
            path: /var/run/cilium
            type: DirectoryOrCreate
          name: cilium-run
          # To keep state between restarts / upgrades for bpf maps
        - hostPath:
            path: /sys/fs/bpf
            type: DirectoryOrCreate
          name: bpf-maps
          # To access iptables concurrently with other processes (e.g. kube-proxy)
        - hostPath:
            path: /run/xtables.lock
            type: FileOrCreate
          name: xtables-lock
        - hostPath:
             path: /root/.kube/config
             type: File
          name: kubeconfig
